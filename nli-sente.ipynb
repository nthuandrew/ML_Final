{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification, BertConfig, BertModel, AutoModel, AutoTokenizer\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download sent_tokenize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_MODEL = \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "      <th>choice</th>\n",
       "      <th>content</th>\n",
       "      <th>question</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>C</td>\n",
       "      <td>{'A': 'Rapid speech without mistakes is a reli...</td>\n",
       "      <td>There is a long-held belief that when meeting ...</td>\n",
       "      <td>Which of the following statements is true acco...</td>\n",
       "      <td>題目/100學測</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>C</td>\n",
       "      <td>{'A': 'Fixing your eyes on the person will mak...</td>\n",
       "      <td>There is a long-held belief that when meeting ...</td>\n",
       "      <td>What is true about fixing your eyes on a perso...</td>\n",
       "      <td>題目/100學測</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>A</td>\n",
       "      <td>{'A': 'Facial expressions.', 'B': 'Physical co...</td>\n",
       "      <td>There is a long-held belief that when meeting ...</td>\n",
       "      <td>Which of the following is NOT discussed in the...</td>\n",
       "      <td>題目/100學測</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>D</td>\n",
       "      <td>{'A': 'People have an instinct for interpretin...</td>\n",
       "      <td>There is a long-held belief that when meeting ...</td>\n",
       "      <td>What is the main idea of the passage?</td>\n",
       "      <td>題目/100學測</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>A</td>\n",
       "      <td>{'A': 'Maasai people are a threat to elephants...</td>\n",
       "      <td>It is easy for us to tell our friends from our...</td>\n",
       "      <td>According to the passage, which of the followi...</td>\n",
       "      <td>題目/100學測</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>47</td>\n",
       "      <td>B</td>\n",
       "      <td>{'A': 'Little palm civets eat only the outer l...</td>\n",
       "      <td>Coffee experts are willing to pay large sums o...</td>\n",
       "      <td>Which of the following statements is true, acc...</td>\n",
       "      <td>題目/99指考</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>48</td>\n",
       "      <td>A</td>\n",
       "      <td>{'A': 'He was the son of a Nazi and a victimiz...</td>\n",
       "      <td>Gunter Grass was the winner of the 1999 Nobel ...</td>\n",
       "      <td>What caused Grass to feel confused and trouble...</td>\n",
       "      <td>題目/99指考</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>49</td>\n",
       "      <td>B</td>\n",
       "      <td>{'A': 'He victimized the Poles and criticized ...</td>\n",
       "      <td>Gunter Grass was the winner of the 1999 Nobel ...</td>\n",
       "      <td>Why has Grass been praised as “the conscience ...</td>\n",
       "      <td>題目/99指考</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>50</td>\n",
       "      <td>C</td>\n",
       "      <td>{'A': 'He was inspired by a fine arts master i...</td>\n",
       "      <td>Gunter Grass was the winner of the 1999 Nobel ...</td>\n",
       "      <td>Why was Grass’s trip to  important to him?</td>\n",
       "      <td>題目/99指考</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>51</td>\n",
       "      <td>D</td>\n",
       "      <td>{'A': 'Most of his poems depict the cruelty of...</td>\n",
       "      <td>Gunter Grass was the winner of the 1999 Nobel ...</td>\n",
       "      <td>Which of the following correctly characterizes...</td>\n",
       "      <td>題目/99指考</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID answer                                             choice  \\\n",
       "0    41      C  {'A': 'Rapid speech without mistakes is a reli...   \n",
       "1    42      C  {'A': 'Fixing your eyes on the person will mak...   \n",
       "2    43      A  {'A': 'Facial expressions.', 'B': 'Physical co...   \n",
       "3    44      D  {'A': 'People have an instinct for interpretin...   \n",
       "4    45      A  {'A': 'Maasai people are a threat to elephants...   \n",
       "..   ..    ...                                                ...   \n",
       "475  47      B  {'A': 'Little palm civets eat only the outer l...   \n",
       "476  48      A  {'A': 'He was the son of a Nazi and a victimiz...   \n",
       "477  49      B  {'A': 'He victimized the Poles and criticized ...   \n",
       "478  50      C  {'A': 'He was inspired by a fine arts master i...   \n",
       "479  51      D  {'A': 'Most of his poems depict the cruelty of...   \n",
       "\n",
       "                                               content  \\\n",
       "0    There is a long-held belief that when meeting ...   \n",
       "1    There is a long-held belief that when meeting ...   \n",
       "2    There is a long-held belief that when meeting ...   \n",
       "3    There is a long-held belief that when meeting ...   \n",
       "4    It is easy for us to tell our friends from our...   \n",
       "..                                                 ...   \n",
       "475  Coffee experts are willing to pay large sums o...   \n",
       "476  Gunter Grass was the winner of the 1999 Nobel ...   \n",
       "477  Gunter Grass was the winner of the 1999 Nobel ...   \n",
       "478  Gunter Grass was the winner of the 1999 Nobel ...   \n",
       "479  Gunter Grass was the winner of the 1999 Nobel ...   \n",
       "\n",
       "                                              question      year  \n",
       "0    Which of the following statements is true acco...  題目/100學測  \n",
       "1    What is true about fixing your eyes on a perso...  題目/100學測  \n",
       "2    Which of the following is NOT discussed in the...  題目/100學測  \n",
       "3                What is the main idea of the passage?  題目/100學測  \n",
       "4    According to the passage, which of the followi...  題目/100學測  \n",
       "..                                                 ...       ...  \n",
       "475  Which of the following statements is true, acc...   題目/99指考  \n",
       "476  What caused Grass to feel confused and trouble...   題目/99指考  \n",
       "477  Why has Grass been praised as “the conscience ...   題目/99指考  \n",
       "478         Why was Grass’s trip to  important to him?   題目/99指考  \n",
       "479  Which of the following correctly characterizes...   題目/99指考  \n",
       "\n",
       "[480 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentences[0] is the sentence in the paragraph(Premise), sentences[1] is the question sentence(Hypothesis)\n",
    "file_path = glob(os.path.join('data', '**', '*.json'), recursive=True)\n",
    "file_path.sort()\n",
    "def read_data(file):\n",
    "    with open(file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    df = pd.DataFrame(data[\"reading_question\"])\n",
    "    df[\"year\"] = data[\"Year\"]\n",
    "    return df\n",
    "data = pd.concat(map(read_data, file_path), ignore_index=True)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(USED_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_question(data):\n",
    "    A, B, C, D = data[\"choice\"].values()\n",
    "    # A_tokenized = tokenizer.batch_encode_plus(list(map(lambda x: data[\"question\"]+A+\"[SEP]\"+x, data[\"content_sent_token\"])), padding=\"max_length\",truncation=True, return_tensors=\"pt\")\n",
    "    # B_tokenized = tokenizer.batch_encode_plus(list(map(lambda x: data[\"question\"]+B+\"[SEP]\"+x, data[\"content_sent_token\"])), padding=\"max_length\",truncation=True, return_tensors=\"pt\")\n",
    "    # C_tokenized = tokenizer.batch_encode_plus(list(map(lambda x: data[\"question\"]+C+\"[SEP]\"+x, data[\"content_sent_token\"])), padding=\"max_length\",truncation=True, return_tensors=\"pt\")\n",
    "    # D_tokenized = tokenizer.batch_encode_plus(list(map(lambda x: data[\"question\"]+D+\"[SEP]\"+x, data[\"content_sent_token\"])), padding=\"max_length\",truncation=True, return_tensors=\"pt\")\n",
    "    A_tokenized = tokenizer(data[\"question\"]+A, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    B_tokenized = tokenizer(data[\"question\"]+B, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    C_tokenized = tokenizer(data[\"question\"]+C, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    D_tokenized = tokenizer(data[\"question\"]+D, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    return (A_tokenized, B_tokenized, C_tokenized, D_tokenized)\n",
    "def tokenize_content(data):\n",
    "    content_token = list(map(lambda x: tokenizer(x, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\"), data[\"content_sent_token\"])) \n",
    "    return content_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"content_sent_token\"] = data[\"content\"].apply(lambda x: sent_tokenize(x))\n",
    "data[\"content_token\"] = data.apply(lambda x: tokenize_content(x), axis=1)\n",
    "data[\"statement_token\"] = data.apply(lambda x: tokenize_question(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(data[\"content_token\"][0][0])\n",
    "# display(data[\"statement_token\"][0][0])\n",
    "# print(tokenizer.decode(data[\"input\"][0][0][\"input_ids\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(USED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "def bert_forward(input, pbar):\n",
    "    model_output = model(**input)\n",
    "    embedding = mean_pooling(model_output, input[\"attention_mask\"])\n",
    "    embedding = F.normalize(embedding, p=2, dim=1)[0]\n",
    "    pbar.update(1)\n",
    "    return embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device=\"cuda\")\n",
    "def move_to_cuda(data):\n",
    "    return list(map(lambda x: x.to(device=\"cuda\"), data))\n",
    "def move_to_cpu(data):\n",
    "    return list(map(lambda x: x.to(device=\"cpu\"), data))\n",
    "data[\"content_token\"] = data[\"content_token\"].apply(lambda x: move_to_cuda(x))\n",
    "data[\"statement_token\"] = data[\"statement_token\"].apply(lambda x: move_to_cuda(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1014]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model_output1 = model(**data[\"content_token\"][0][0])\n",
    "    model_output2 = model(**data[\"statement_token\"][0][0])\n",
    "sentences1_embedding = mean_pooling(model_output1, data[\"content_token\"][0][0][\"attention_mask\"])\n",
    "sentences2_embedding = mean_pooling(model_output2, data[\"statement_token\"][0][0][\"attention_mask\"])\n",
    "sentences1_embedding = F.normalize(sentences1_embedding, p=2, dim=1)[0]\n",
    "sentences2_embedding = F.normalize(sentences2_embedding, p=2, dim=1)[0]\n",
    "print(util.dot_score(sentences1_embedding, sentences2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8428/8428 [00:26<00:00, 313.10it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=sum(data[\"content_embedding\"].apply(len))+sum(data[\"statement_embedding\"].apply(len))) as pbar: \n",
    "    with torch.no_grad():\n",
    "        data[\"content_embedding\"] = data[\"content_token\"].apply(lambda x: list(map(lambda y: bert_forward(y, pbar), x)))\n",
    "        data[\"statement_embedding\"] = data[\"statement_token\"].apply(lambda x: list(map(lambda y: bert_forward(y, pbar), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"content_embedding\"].apply(lambda x: print(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# list to tensor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mcontent_embedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39;49m\u001b[39mcontent_embedding\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: torch\u001b[39m.\u001b[39;49mstack(x))\n\u001b[1;32m      3\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mstatement_embedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mstatement_embedding\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: torch\u001b[39m.\u001b[39mstack(x))\n",
      "File \u001b[0;32m~/ML_Final/ML_final_py/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/ML_Final/ML_final_py/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/ML_Final/ML_final_py/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/ML_Final/ML_final_py/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[219], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# list to tensor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mcontent_embedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mcontent_embedding\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: torch\u001b[39m.\u001b[39;49mstack(x))\n\u001b[1;32m      3\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mstatement_embedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mstatement_embedding\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: torch\u001b[39m.\u001b[39mstack(x))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# list to tensor\n",
    "data[\"content_embedding\"] = data[\"content_embedding\"].apply(lambda x: torch.stack(x))\n",
    "data[\"statement_embedding\"] = data[\"statement_embedding\"].apply(lambda x: torch.stack(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    statement = data[\"statement_embedding\"]\n",
    "    content = data[\"content_embedding\"]\n",
    "    score = torch.mm(s, c.T).sum(dim=1)\n",
    "    return score\n",
    "data[\"predict_score\"] = data.apply(lambda x: predict(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which of the following is true regarding Japan’s national anthem?\n",
      "{'A': 'It was not written until the 20th century.',\n",
      " 'B': 'The lyrics was written by a Japanese officer.',\n",
      " 'C': 'The melody was first composed by a British musician.',\n",
      " 'D': 'The current version is barely influenced by western music.'}\n",
      "During the past three hundred years, when a country gains its freedom or independence, one of the first things established is a national anthem.\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "print(data[\"question\"][question])\n",
    "pprint(data[\"choice\"][question])\n",
    "print(data[\"content_sent_token\"][question][0])\n",
    "print(data[\"answer\"][question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([[5.3357]]), B: tensor([[5.3111]]), C: tensor([[5.8168]]), D: tensor([[6.2368]])\n"
     ]
    }
   ],
   "source": [
    "statement1 = data[\"statement_embedding\"][question][0]\n",
    "statement2 = data[\"statement_embedding\"][question][1]\n",
    "statement3 = data[\"statement_embedding\"][question][2]\n",
    "statement4 = data[\"statement_embedding\"][question][3]\n",
    "content = data[\"content_embedding\"][question]\n",
    "socre1 = 0\n",
    "socre2 = 0\n",
    "socre3 = 0\n",
    "socre4 = 0\n",
    "for i in range(len(content)):\n",
    "    socre1 += util.dot_score(statement1[0], content[i])\n",
    "    socre2 += util.dot_score(statement2[0], content[i])\n",
    "    socre3 += util.dot_score(statement3[0], content[i])\n",
    "    socre4 += util.dot_score(statement4[0], content[i])\n",
    "print(f\"A: {socre1}, B: {socre2}, C: {socre3}, D: {socre4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoModelForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# use all-MiniLM-L6-v2 to compare the sentecnse by NLI and create label for the sentences\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(sentences[\u001b[39m0\u001b[39m], sentences[\u001b[39m1\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "# use all-MiniLM-L6-v2 to compare the sentecnse by NLI and create label for the sentences\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "inputs = tokenizer(sentences[0], sentences[1], return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts the probability of the label\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "# get the index of the label with the highest probability\n",
    "pred = torch.argmax(probs, dim=1)\n",
    "print(pred)\n",
    "\n",
    "# get the probability of the label\n",
    "print(probs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_final_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6273f2935998ed9bb80b3a175896a2488b06412ab449d5916a38f39c7b99953d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
